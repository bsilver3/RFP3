{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "# env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False, render_mode='human')\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False)\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom rewards\n",
    "custom_rewards = {\n",
    "    'S': 0.0,  # Reward for frozen tiles (very small positive reward)\n",
    "    'F': -0.75,  # Reward for falling in a hole (negative reward)\n",
    "    'G': 1.0,   # Reward for reaching the goal (the \"gift\" state)\n",
    "}\n",
    "\n",
    "# Map custom rewards to the environment's reward table\n",
    "env.env.rewards = custom_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom policy to avoid edges\n",
    "def custom_policy(state):\n",
    "    if state % 4 == 0:  # Agent is at leftmost column\n",
    "        return [1, 2, 3]  # Avoid going left\n",
    "    elif state % 4 == 3:  # Agent is at rightmost column\n",
    "        return [0, 1, 3]  # Avoid going right\n",
    "    elif state < 4:  # Agent is at top row\n",
    "        return [0, 1, 2]  # Avoid going up\n",
    "    elif state > 15:  # Agent is at bottom row\n",
    "        return [0, 2, 3]  # Avoid going down\n",
    "    else:\n",
    "        return [0, 1, 2, 3]  # All actions are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table with zeros\n",
    "Q = np.random.rand(env.observation_space.n, env.action_space.n) * 0.01\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.8\n",
    "discount_factor = 0.95\n",
    "epsilon = 1.0\n",
    "max_exploration_rate = 1.0\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.001\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.00919797244170492\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.009861686274302893\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.025983422449589892\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.007257882824659965\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.057687668245627904\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.12254538687112582\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02655643628636089\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6100885658466066\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.014539223399425535\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6110345577386213\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.016159328152222915\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 3\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.028528189649268815\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.009276200885307253\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6103045310210117\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.026281778303278096\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.013661370524493701\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.007371698969196608\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.026993474590284172\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 3\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.06017723697461921\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.03935403448891384\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.037719738316548894\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.056944085551606294\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.07963899725927084\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.13633476532148817\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.028880523099439295\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.058197284175494704\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 2\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.12396459016427783\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6085928651028896\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.017861524760512577\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.027642405267251032\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012907391873922982\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.028743519745724515\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.00982158312527721\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 1\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.06203964516358746\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6102355069411051\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.02938192277628398\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01856996481547444\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04611014337573159\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04317839613830557\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01249773368257484\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008732051509680212\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.025616022598840764\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6106267786558821\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04288461255836758\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.058536709056560984\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.034133956826418\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.017993624139572163\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.010534382369504998\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6105400820001582\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.050518729699751186\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06593176822093648\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.06804555312802792\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.036501945711358445\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.02623508397527139\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012869030086465807\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.00807930239613834\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.7899841229947251\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07066632212954203\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.057350589366238006\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04323905296347795\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.029253147395878077\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.014758906201816083\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04089941805727062\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.014010068435112646\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6102213413757324\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.060331798125490846\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04649288559944622\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.05959377895589553\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.032498281489861225\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01553297299759701\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6095063301119328\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06340095268067729\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.049997271052183774\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03371642501135247\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01690263940552301\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6108830770987166\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06667811653579513\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05162393721906463\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03454834448044422\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.02524686442058454\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5827720729967634\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9462343222003733\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06856981559364814\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.052581529248950536\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.035755674844286336\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01736025086249832\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.009343599389023013\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6078177386367026\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06967592534793204\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.053690618731447724\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.036344925624355984\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.026573185708157157\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012228400948361771\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.024875386615440642\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008787829573704374\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02440184288158658\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6114085602058653\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07074005530548669\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05436026722080009\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.042456602084515446\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4218574025934232\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8196924994716364\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.977484362041503\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.08383966924436036\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.0714618141489054\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05913907102839176\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.2961203055540985\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6913377801171282\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8908266150458696\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.983734370009729\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07478026171276743\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.08601935254589055\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.09144395122553983\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.12019524069429856\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.19722361801543653\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5686407739998371\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7992957834582866\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9098034442165679\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9849843716033742\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05360922358529846\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 3\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.059387062063298066\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.0642869575881366\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.11985601188516623\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 3\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.18501157958076614\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.10857554014334118\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.14448608247458594\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.1156011594466238\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4556117118429635\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7051929502282652\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8353097742962489\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9145488112618779\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852343719221032\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.353385132889977\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6110689845420743\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7598740185108022\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8461190514182769\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.915687884913174\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.010736994868786987\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 16\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.026274205818241254\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7179237925278498\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.985284371985849\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5190894548299718\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6837180509766245\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7790252827800509\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8491466028176676\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9159536996918799\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852943719985982\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.607443609708229\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7128028251081635\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7851564746974375\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8499541323293622\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160144626573105\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.985296372001148\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6472188690238501\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7232794857916851\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7869964355098028\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8501618180854283\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160281352523344\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852967720016579\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6631361830064506\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7267731881457871\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.787522268846886\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502137464088597\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160311737717268\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968520017599\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6689748595920882\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7278715619527907\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876669010401105\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502264413482843\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160318422756828\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968680017803\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6709773590025385\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7282011571810421\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877054756327181\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502294883991757\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160319881364896\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968712017843\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6716283512580996\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7282963929170742\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.787715506309917\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502302086635671\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.916032019740654\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968718417852\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718309288685963\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283230633789517\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877180598462944\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502303767356103\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320265478875\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968719697853\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718917139417225\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283303381589741\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877186982883227\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304155235165\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320280066143\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968719953854\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719093997891648\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283322783309201\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188554555371\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304243897302\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320283178157\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720005054\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719144114893322\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283327858123922\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188936273023\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304263994859\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320283839472\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5274746833474084\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.860410381225954\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720015294\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719157995152845\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329163192281\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189027890696\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304268516969\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320283979517\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017342\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719161763056702\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329493835385\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189049651036\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269527826\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284009082\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017752\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162767926233\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329576501864\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189054771355\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269752468\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284015308\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017834\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163031726663\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329596926602\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189055966146\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269802127\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016615\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.985296872001785\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916310000955\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329601919591\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056242845\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269813052\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016888\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017853\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163117460799\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960312848\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056306488\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815445\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016945\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121869803\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603418627\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056321036\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815967\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016957\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122972116\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603487712\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056324342\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981608\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.916032028401696\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123245083\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603504042\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325089\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816104\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123312089\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603507875\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325257\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816111\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328402\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350877\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325296\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332346\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508978\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325303\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333292\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509026\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333517\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509037\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333571\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509039\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333584\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333587\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.5542584392480058\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7717189056325305\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.716172960350904\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7845189056325306\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6626747123333588\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.723468960350904\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7870789056325306\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6663713523333589\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.726873760350904\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7875909056325305\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6696983283333587\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727943840350904\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876933056325306\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6711769843333587\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728235680350904\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877137856325306\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6716945139333588\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728309613150904\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877178816325305\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718542087813588\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728327512670904\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877187008325306\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718997513861588\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728331715166904\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188646725306\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719120538040787\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332680184504\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188974405306\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719152477010387\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283328980917041\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189039941306\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719160520899029\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329466538799\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189053048506\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162498749293\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329573624624\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189055669945\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162975704572\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329597034083\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056194234\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163088886817\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329602114434\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056299091\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163115384333\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603210196\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056320063\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121516615\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603445287\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056324257\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122921741\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603495493\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325096\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123240923\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603506171\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325263\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123312875\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508434\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325297\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328984\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508911\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325303\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7434068264012067\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8889076989665476\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332569\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509012\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333363\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509034\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333538\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509039\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333577\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333586\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8082512164948176\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8946071625146663\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6775180561303243\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7717189056325305\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value 0.5770519199862564\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8342304269816112\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.716172960350904\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7723589056325305\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8470304269816112\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6626747123333588\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.714227360350904\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7822149056325306\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8495904269816112\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6593477363333587\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.721328800350904\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7861317056325307\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8501024269816112\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6640794355333587\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.725725856350904\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7873041856325306\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502048269816113\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6683675379333588\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727496352350904\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876165056325307\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502253069816113\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6705707353733588\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7280878147509041\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876945344325307\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502294029816112\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6714608862853588\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7282654091189041\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877132531525306\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502302221816113\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6717738881874389\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728315154219704\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.5122974885318287\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.712325103239864\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877176194885307\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502303860216113\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6597218560997844\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7251304114592562\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877186172741307\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304187896113\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6670434839289916\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7276922314201906\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188417349307\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304253432112\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6704547926651431\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7282047660025853\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188916078266\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304266539312\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6715265806949934\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283073108224652\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189025785529\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269160752\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718188723640722\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283278281241933\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189049719276\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426968504\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718929238472013\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283319334035037\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189054904485\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269789898\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719108541561031\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283327548534416\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056021219\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981087\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719150645198362\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329192283009\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056260505\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815064\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719160315174759\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329521214585\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.787718905631155\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815902\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162499158036\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329587039694\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056322396\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981607\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162985981775\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329600212959\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056324692\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816103\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163093358204\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329602849357\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325177\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981611\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163116837151\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603377006\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325279\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121933954\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603482612\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.78771890563253\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123033576\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350375\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325304\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123269565\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603507981\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123319978\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508828\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123330705\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508998\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332978\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4774525268641282\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6559163123333434\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509031\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.668716312333355\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509038\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6712763123333578\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6717883123333586\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718907123333587\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719111923333588\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719152883333588\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719161075333588\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162713733589\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163041413588\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163106949588\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163120056788\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122678228\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123202516\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123307373\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328346\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312333254\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333378\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333546\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333579\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333586\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8255516868101099\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8957470552242901\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7334665932251369\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4701473199991275\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5901469027461783\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6559163123333588\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6687163123333588\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6712763123333588\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6717883123333588\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718907123333588\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719111923333588\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719152883333588\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719161075333588\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162713733589\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163041413588\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163106949588\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163120056788\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122678228\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123202516\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123307373\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328346\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312333254\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333378\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333546\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333579\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333586\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7324137053657921\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6239925475730528\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.712332960350904\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6597563123333587\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.725132960350904\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6670523123333587\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727692960350904\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6704571123333587\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728204960350904\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6715271923333588\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728307360350904\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718190323333588\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728327840350904\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718929651333588\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728331936350904\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719108646533587\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332755550904\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8298780993324824\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8959750337662149\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719150671493588\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332919390904\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719160321669588\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332952158904\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162500741588\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332958712504\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162986363347\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960023224\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163093449172\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960285368\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.12248861288597254\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4729412870734688\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163116858631\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603377968\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121938982\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603482825\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123034744\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603503798\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123269835\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603507992\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123320041\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350883\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123330719\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508998\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332982\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509031\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333459\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509038\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312333356\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333582\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333587\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6126857779225883\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6559163123333588\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6687163123333588\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6712763123333588\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6717883123333588\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718907123333588\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719111923333588\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719152883333588\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719161075333588\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162713733589\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163041413588\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163106949588\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163120056788\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122678228\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123202516\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123307373\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328346\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312333254\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333378\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333546\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333579\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333586\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7322678699999576\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7295855085032757\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8342304269816112\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7755589056325306\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8470304269816112\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.719091360350904\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7828549056325306\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8495904269816112\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6648926963333588\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7227880003509041\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7862597056325306\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8501024269816112\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6662974195333589\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.726114976350904\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7873297856325306\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502048269816113\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6691068659333588\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727593632350904\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876216256325307\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502253069816113\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6707925337733588\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7281111619509041\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876955584325307\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502294029816112\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6715229898373588\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7282708567989041\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877134579525306\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502302221816113\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6717904491346388\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283163994037041\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877176604485306\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502303860216113\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718785533737428\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283287018216241\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877186254661307\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304187896113\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719055240591828\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283318957185841\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188433733306\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304253432112\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719133455579605\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283327001074481\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188919355066\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304266539312\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719155211932526\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283328978924746\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.787718902644089\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269160752\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719161066369312\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329455880024\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189049850348\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426968504\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162599742681\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329569062269\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.78771890549307\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269789898\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916299243586\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329595559785\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056026461\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981087\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163091112609\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329601692067\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056261553\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815064\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163115508492\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603097194\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.787718905631176\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815902\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121455565\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603416376\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056322438\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981607\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122887559\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603488328\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.78771890563247\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816103\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312322864\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603504437\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325178\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.850230426981611\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.67191631233091\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508022\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325279\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123327916\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508816\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.78771890563253\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332283\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508991\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325304\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333289\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509029\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333519\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509038\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333572\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6463315593812976\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.712332960350904\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6597563123333584\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.725132960350904\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6670523123333587\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727692960350904\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6704571123333587\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728204960350904\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6715271923333588\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728307360350904\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718190323333588\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728327840350904\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718929651333588\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728331936350904\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719108646533587\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332755550904\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719150671493588\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332919390904\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719160321669588\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332952158904\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162500741588\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332958712504\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162986363347\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960023224\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163093449172\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960285368\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163116858631\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603377968\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121938982\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603482825\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123034744\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603503798\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123269835\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603507992\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123320041\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350883\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123330719\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508998\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332982\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509031\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333459\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509038\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312333356\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333582\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333587\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5886858613731781\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6657544782260105\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.900032028401696\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8380704269816113\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9128320284016961\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7784773056325306\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8453664269816112\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9153920284016961\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.721309344350904\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7821739456325306\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8487712269816112\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.915904028401696\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6665783641733588\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7227140675509041\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7855009216325306\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8498413069816112\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160064284016961\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6665783641733588\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.725523513950904\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7869795776325306\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8501331469816112\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160269084016961\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6687135434373587\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727209181790904\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7874971072325306\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502070797816113\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.916031004401696\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6704216868485587\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727939637854904\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876568020805306\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502249793016112\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160318236016961\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6713184621394388\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728207097152184\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877023446853306\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502291817976112\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160319874416961\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6717010862635475\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7282952013912881\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877146471032506\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502301468152113\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320202096961\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718445703100884\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728322172076728\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877178410002106\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502303647224113\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320267632961\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718937648403309\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283299935755057\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877186453890747\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304132845873\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320280740161\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719095480854504\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7339207896155518\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719127047344743\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283321692107978\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188431741012\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304239931696\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.91603202833616\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719149895471012\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283327546544764\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188908696291\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304263341155\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320283885889\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719158914468223\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329079918133\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189021878536\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304268421507\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320283990746\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719161883631425\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329472611313\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189048376052\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269517268\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284011718\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162775910882\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329571288062\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189054508333\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269752359\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284015913\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163029361103\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329595683945\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189055913459\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269802565\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016751\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163098592019\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329601631018\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056232642\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269813243\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016918\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163116957977\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603063011\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056304593\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815506\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016952\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121719484\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603404093\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056320703\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269815983\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016958\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122931007\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603484552\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056324287\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816084\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.671916312323446\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603503369\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325081\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816107\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123309452\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603507736\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325257\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816111\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123327768\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508741\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325296\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332197\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508972\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325303\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333258\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509024\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333509\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509037\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333569\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509039\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333584\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333587\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8309166455288197\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8960206294745998\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03060822186238638\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01408324649328118\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.041555258467422335\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04149539977467156\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.013548768557739019\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.07318948585203908\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.03435145548178104\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.00849519409910418\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.022639347082447418\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 2\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.055114670904925854\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.7900427860785953\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7581156435950177\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7568493450507294\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.761736472987717\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05320520209600295\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6059952408945704\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6123935696479882\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7630454536689939\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7627138985751144\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6171351113029503\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7586872343693409\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7568201779775625\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8311590075064598\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8960297486162768\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7636405233200987\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7646311811102503\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7021699795067881\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7717189056325305\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.716172960350904\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7845189056325306\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6626747123333588\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.723468960350904\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7870789056325306\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6663713523333589\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.726873760350904\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7875909056325305\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6696983283333587\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727943840350904\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876933056325306\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6711769843333587\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728235680350904\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877137856325306\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6716945139333588\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728309613150904\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877178816325305\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718542087813588\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728327512670904\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877187008325306\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718997513861588\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728331715166904\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188646725306\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719120538040787\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332680184504\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188974405306\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719152477010387\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283328980917041\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189039941306\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719160520899029\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329466538799\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189053048506\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162498749293\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329573624624\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189055669945\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162975704572\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329597034083\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056194234\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163088886817\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329602114434\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056299091\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163115384333\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603210196\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056320063\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121516615\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603445287\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056324257\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122921741\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603495493\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325096\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123240923\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603506171\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325263\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123312875\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508434\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325297\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328984\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7648293126682806\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332206\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508911\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325303\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333213\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509012\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333491\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509034\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333565\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509039\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333582\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333587\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.43391534266067294\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7353741726849385\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.31893765559864173\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5892446547880463\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6296674397726878\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7612499590430122\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7648689389798866\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7071003641820808\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7717189056325305\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333588\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.716172960350904\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7845189056325306\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6626747123333588\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.723468960350904\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7870789056325306\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6663713523333589\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.726873760350904\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7875909056325305\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6696983283333587\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.727943840350904\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7876933056325306\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6711769843333587\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728235680350904\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877137856325306\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6716945139333588\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728309613150904\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877178816325305\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718542087813588\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728327512670904\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877187008325306\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718997513861588\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728331715166904\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188646725306\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719120538040787\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332680184504\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877188974405306\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719152477010387\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283328980917041\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189039941306\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719160520899029\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329466538799\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189053048506\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162498749293\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329573624624\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189055669945\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719162975704572\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329597034083\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056194234\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163088886817\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329602114434\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056299091\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163115384333\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603210196\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056320063\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163121516615\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603445287\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056324257\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163122921741\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603495493\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325096\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123240923\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603506171\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325263\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123312875\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508434\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325297\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123328984\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603508911\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325303\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123332569\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509012\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333363\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509034\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333538\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7283329603509039\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333577\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6719163123333586\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.728332960350904\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7877189056325306\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8502304269816112\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9160320284016961\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 0\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9852968720017854\n",
      "--------NEXT--------\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state_tuple = env.reset()  # State is a tuple\n",
    "    state = state_tuple[0]  # Extract the integer state value\n",
    "    done = False\n",
    "\n",
    "    # Reset state visits count for the new episode\n",
    "    state_visits = {s: 0 for s in range(env.observation_space.n)}\n",
    "\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(custom_policy(state))  # Custom policy\n",
    "        else:\n",
    "            action = np.argmax(Q[state, :])\n",
    "\n",
    "        print(\"Episode:\", episode)\n",
    "        print(\"Action:\", action)\n",
    "\n",
    "        # Take action and observe the next state, reward, done flag, and info\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        next_state = step_result[0]  # Extract the next state tuple\n",
    "        reward = step_result[1]  # Extract the reward\n",
    "        terminated = step_result[2]  # Extract the done flags\n",
    "        truncated = step_result[3] # Extract the done flags\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Update state visits count\n",
    "        state_visits[next_state] += 1\n",
    "\n",
    "        # Calculate penalty for visiting the same state\n",
    "        visit_penalty = -0.01 * (2 ** state_visits[next_state])\n",
    "\n",
    "        # Check if the agent stayed in the same state\n",
    "        if next_state == state:\n",
    "            reward = visit_penalty\n",
    "        else:\n",
    "            # Check for falling into the ice\n",
    "            if terminated and reward == 0:\n",
    "                reward = custom_rewards[\"F\"]  # Penalty for falling into the ice\n",
    "            elif not terminated:\n",
    "                reward = custom_rewards[\"S\"]  # Reward for a safe move\n",
    "            reward += visit_penalty  # Add penalty for repeated visits\n",
    "\n",
    "        # Update Q-value using SARSA formula\n",
    "        next_action = np.argmax(Q[next_state, :])\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * Q[next_state, next_action] - Q[state, action])\n",
    "\n",
    "        # Decay the exploration rate\n",
    "        epsilon = max(min_exploration_rate, epsilon * exploration_decay_rate)\n",
    "\n",
    "        print(\"Step Result:\", step_result)\n",
    "        print(\"State Tuple:\", state_tuple)\n",
    "        print(\"State:\", state)\n",
    "        print(\"New State:\", next_state)\n",
    "        print(\"Next Action:\", next_action)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        print(\"New Q-Value\", Q[state, action])\n",
    "        print(\"--------NEXT--------\")\n",
    "\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('frozenlake_qtable.npy', Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
